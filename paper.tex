\documentclass[conference]{IEEEtran}
	\pdfpagewidth=8.5truein
	\pdfpageheight=11truein

\usepackage{graphicx}
\usepackage{subfig}
\usepackage[bookmarks=false]{hyperref}
\usepackage{xspace}
\usepackage{listings}
\usepackage[usenames, dvipsnames]{color}
\usepackage{amssymb}



\usepackage{booktabs}         

\graphicspath{{./img/}}

%\hyphenation{op-tical net-works semi-conduc-tor}

\input{useful_defines}


\begin{document}
	

% An Agile Analytics Platform for Visualizing Evolving Flask-Based Python Web Services
% A Dashboard for the Agile Monitoring of Evolving Web Services: For the Little Man
% A Dashboard for Monitoring Flask \& Python-Based Web Service Evolution
% Monitoring the Evolution of Flask \& Python-Based Web Services
% A Dashboard for Monitoring the Evolution of Flask \& Python-Based Web Services
% Continuously Monitoring the Evolution of Flask \& Python-Based Web Services
% A Dashboard for Continuously Monitoring the Evolution of Flask \& Python-Based Web Services
\title{Continuously Monitoring the Evolution of Flask \& Python-Based Web Services}

\author{
\IEEEauthorblockN{Author One, Segundo Autor, Troisi\`eme Auteur}\\
Famous Institute for Software Engineering and Computer Science\\
University of Great City, Some Country\\
Email: \{first.last\}@university.to 
}


% make the title area
\maketitle

\input{introductory}

\input{loc1}

\input{utilization}

\input{performance}

\input{outliers}

\input{grouping}

\input{evolution}

\input{testing}

\input{overhead}

% \input{architecture}

\input{discussion}

\input{related-work}


\section{Conclusion and Future Work}
\label{sec:conclusions}

In the previous sections we discussed our proposal for a monitoring dashboard for Flask-based web applications as the means for providing a low effort and flexible analytics solution to projects on a budget. The emphasis is in allowing application developers to gain insight into how the performance and utilization of their services evolves together with the application itself. For this purpose the \tool allows for integration with both \git and the Travis CI platform. We also discussed more advanced features of the dashboard in the form of grouping results by user groups, and provided evidence towards the use of unit testing-sourced synthetic loads as a potential limited form of performance prediction. Finally we measured the overhead of the proposed solution within acceptable by the case study application owner limits. Section~\ref{sec:discussion} which discusses what we perceive as limitations of our proposal and also potential challenges for other similar tools, effectively acts also as a roadmap for further development, with the ultimate goal of increasing the adoption of the \tool by as many projects as possible. This will allow us to evaluate our proposal in depth in the future.

% Some of the tasks have already been identified as ongoing work (allowing different types of grouping, enabling performance prediction, developing a meta-dashboard) while others constitute short- to medium-term future work (identification of important versions to be monitored, support for endpoint provenance) 

%\todo{update as appropriate}
%
%In this paper we have shown that it is possible to create a monitoring solution which provides basic insight into web service utilization and performance  with very little effort from the developer. The user group that we are aiming for with this work is application developers using Flask and Python to build web applications with limited or no budget for implementing their own monitoring solutions. The emphasis is in allowing such users to gain insight into how the performance of the service evolves together with the application itself. We believe that the same architecture, and lessons can be applied to other frameworks and other languages.
%
%In the future, we plan to perform case studies with other sytstems, with the goal of discover other needs and to wean out the less useful visualizations in the \tool. We plan to also extend the tool towards supporting multiple deployments of the same applications across multiple nodes (e.g. for the situations where the application is deployed together with a load balancer). Finally, we plan to integrate \tool with unit testing as a complementary source of information about performance evolution.



% \input{appendix}


% references section

\bibliographystyle{abbrv}
\bibliography{paper}


% that's all folks
\end{document}


